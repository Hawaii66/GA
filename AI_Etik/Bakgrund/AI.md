- Typer av AI
- Narrow vs General
- Fokus på general
- Pretrained vs not

- Träningsdata

- Types of AI

## Typer av AI

Olika AI modeller kan i ett system klassas under 3 kategorier, snäv, generell och super. Den första kategorin av AI finns idag i olika AI modeller medan super och generell AI endast är ett koncept skriver internetkunskap[^1]. Super AI är en AI modell som är bättre än människan i bemärkelsen att den är mer kapabel att utföra uppgifter på en betydligt högre nivå än människor. Generel AI skriver internetkunskap[^1] kan `utföra precis vilken intellektuell uppgift som helst`[^1]. Det som idag saknas för att man ska uppnå generell och super AI är att de idag inte är självmedvetna, människor känner till sin egen existens. Snäv AI är AI modeller som är speciferade på att klara specifika uppgifter och är därmed tränade endast för dessa uppgifter och har på grund av de en small förståelse. All AI som finns idag är snäv AI med olika grader av snävhet och specificitet.
Exempel på snäva ai som har en hög specificitet är modeller som kan identifiera bokstäver i en bok. Modellen behöver bara om man utgår från ASCII karaktärer kunna definera 128 olika karaktärer. En AI som är mer generaliserad är exempel vis AI:n bakom spel där AI:n ska simulera människors förväntade beteende. Några av de mest komplicerade och därmed minst snäva ain som finns idag är olik chatbottar som ChatGPT och Bing Chatt samt olika bild genererings verktyg, exempelvis Midjourney och Dall-E.

#### Fokus på Snäv AI

I denna litteratur studie kommer främst olika mindre snäva ai modeller att jämföras och disskuteras med fokus på ChatGPT från OpenAI och Midjourney.

### Förtränad och icke förtränad modeller

Heartbeat [^2] skriver att en förtränad modell har tränats på större och mer generella dataset. Då de tränas på stora mängder data i många olika områden kan de göra komplingar mellan domäner och hitta mönster i datan. Motsatsen mot förtränade modeller är icke förtränade modeller. Dessa modeller tränas endast för att klara av en specifik uppgift. Modellernas domänområden är därmed mindre och de kan inte skapa kopplingar och mönster på sammas sätt. Däremot har de möjligheten att fokussera allt på ett specifikt område och kan därmed bli mindre till storlek och snabbare att köra.
Fördelar med förtränade modeller är då att de kan hitta mönster mellan domäner och användas i flera applikationer utan att om tränas för en ny specifik uppgift. Överanpassning kan dock leda till bias och problem med att träna modellen på tillräckligt stora mängder data. Modellerna tenderar också att bli stora och ta längre tid att köra, inga specifika nummer har gets ut men man estimerar GPT-3.5 att ta upp runt 500GB [^3]. Icke förtränade modeller är mer skräddarsydda och kräver därmed inte lika mycket träningsdata och resurser.

[^1]: https://internetkunskap.se/artiklar/ordlista/artificiell-intelligens/
[^2]: https://heartbeat.comet.ml/pre-trained-machine-learning-models-vs-models-trained-from-scratch-63e079ed648f
[^3]: https://www.reddit.com/r/ChatGPT/comments/zhzjpq/how_big_is_the_model/
